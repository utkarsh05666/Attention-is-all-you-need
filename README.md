# Attention Is All You Need Paper Implementation

This is my from-scratch implementation of the original transformer architecture from the following paper: [Vaswani, Ashish, et al. "Attention is all you need." Advances in neural information processing systems. 2017.](https://arxiv.org/abs/1706.03762)

<a href=https://arxiv.org/pdf/1706.03762.pdf>
  <p align="center">
    <img width="540" height="700" src="https://user-images.githubusercontent.com/57716666/143226016-e184793b-a0c8-443c-b2c0-8f034eb82d93.jpg">
  </p>
</a>

